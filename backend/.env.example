# WR-AI Backend Environment Configuration
# Copy this file to .env and configure your settings

# ===========================================
# LLM Configuration
# ===========================================

# LLM Provider: "ollama" (local) or "gemini" (cloud)
LLM_PROVIDER=ollama

# Ollama Configuration (when LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:latest

# Gemini Configuration (when LLM_PROVIDER=gemini)
# Get your API key from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your-gemini-api-key-here

# ===========================================
# Server Configuration
# ===========================================

# API Server
HOST=0.0.0.0
PORT=8000

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# ===========================================
# Anomaly Detection Configuration
# ===========================================

# Detection loop interval in seconds
ANOMALY_CHECK_INTERVAL=2

# Thresholds (optional, defaults in service.py)
# VIBRATION_WARNING_THRESHOLD=4.0
# VIBRATION_CRITICAL_THRESHOLD=6.0
# TEMPERATURE_WARNING_THRESHOLD=75.0
# TEMPERATURE_CRITICAL_THRESHOLD=85.0
